{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import ast\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from shared import generate\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *Persona Based Analysis* - Workplace #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Generate Workplace Persona Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_workplace_interaction():\n",
    "  return generate(model = '4o-mini',\n",
    "        system = \"Generate fictional personas for two individuals who are professional colleagues. Use these personas to write a brief workplace dialogue.\",\n",
    "        query = 'Write a professional workplace interaction between the two colleagues imagined above. Limit the exchange to no more than 4 messages. Do not use names or pronouns. Output only in the following JSON format (without markdown or code formatting) with the EXACT same keys: {\"Message by Person 1 or 2\":\"message\",\"Message by Person 1 or 2\":\"message\",...}.',\n",
    "        temperature=1.5,\n",
    "        lastk=0,\n",
    "        session_id='new',\n",
    "        rag_usage = True,\n",
    "        rag_threshold = 0,\n",
    "        rag_k = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dialogue(i):\n",
    "    return generate_workplace_interaction()['response']\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=10) as executor:\n",
    "    results = list(executor.map(process_dialogue, range(100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('persona_generated_data/workplace.json', 'w') as f:\n",
    "    json.dump(results, f, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Analyse Workplace Persona Data** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_workplace_persona(dialogue):\n",
    "  return generate(model = '4o-mini',\n",
    "        system = 'Analyze the dialogue as specified below.',\n",
    "        query = dialogue + '\\n\\nThe dialogue above features two colleagues. Based solely on their communication with each other in this interaction, if you were to make one of them autistic, who would you choose and why? Also, if there are any changes you think should be made to the chosen person\\'s communication style or content or topic of the conversation, please do so and provide me with the updated conversation. Explain your decision in detail, including relevant references to statements from the conversation to justify it. Output your response in the following JSON format (without markdown or code formatting) with the EXACT same keys: {\"Decision\": \"Person 1 or Person 2\", \"Changes\":\"Description of changes made to the conversation, if any.\", \"Updated Conversation\":{\"Person 1\":\"their statement...\", \"Person 2\": \"their statement...\"}, \"Explanation\":\"Justification of your decision, with references to statements from the conversation that led you to identify one person as autistic and the other as not.\",}',\n",
    "        temperature=1,\n",
    "        lastk=0,\n",
    "        session_id='new',\n",
    "        rag_usage = True,\n",
    "        rag_threshold = 0,\n",
    "        rag_k = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['{\"Message by Person 1\":\"The quarterly report is due next week. Have all the metrics been reviewed for accuracy?\",\"Message by Person 2\":\"I finished analyzing the data yesterday. I\\'m just compiling it into the presentation format now.\",\"Message by Person 1\":\"Great! Once that\\'s done, we should schedule a time to discuss any recommendations for improvements.\",\"Message by Person 2\":\"Sounds perfect. I will aim to have it ready by tomorrow afternoon.\"}',\n",
       " '{\"Message by Person 1\":\"The marketing presentation is due next week. I hope the graphics are ready by tomorrow.\",\"Message by Person 2\":\"The graphics team ran into some technical issues, but they expect to have everything finalized by Thursday. Hoping that\\'s soon enough for us.\",\"Message by Person 1\":\"That works. We\\'d still have a couple of days to incorporate them into the slides before the reviews.\",\"Message by Person 2\":\"Exactly! I’ll touch base with the graphics team and make sure they stay on track.\"}']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('persona_generated_data/workplace.json') as f:\n",
    "    results_loaded = json.load(f)\n",
    "\n",
    "results_loaded[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dialogue(i):\n",
    "    dialogue = results_loaded[i]\n",
    "    response = analyze_workplace_persona(dialogue)['response']\n",
    "    return response\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=10) as executor:\n",
    "    results = list(executor.map(process_dialogue, range(100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('persona_analysis_data/workplace.json', 'w') as f:\n",
    "    json.dump(results, f, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Process Workplace Persona Analysis Data** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fixed 100 entries. Saved to persona_analysis_data/fixed_workplace.json\n"
     ]
    }
   ],
   "source": [
    "def fix_and_validate_json(input_path, output_path):\n",
    "    with open(input_path, 'r', encoding='utf-8') as f:\n",
    "        raw_data = json.load(f)\n",
    "\n",
    "    fixed_data = []\n",
    "    decoder = json.JSONDecoder()\n",
    "\n",
    "    for i, entry in enumerate(raw_data, 1):\n",
    "        if not isinstance(entry, str):\n",
    "            print(f\"[Warning] Entry {i} is not a string. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        fixed = None\n",
    "\n",
    "        # Try multiple parsing approaches\n",
    "        for attempt in range(3):\n",
    "            try:\n",
    "                if attempt == 0:\n",
    "                    fixed = json.loads(entry)\n",
    "                elif attempt == 1:\n",
    "                    # Unescape unicode, then parse\n",
    "                    unescaped = entry.encode('utf-8').decode('unicode_escape')\n",
    "                    fixed = json.loads(unescaped)\n",
    "                elif attempt == 2:\n",
    "                    # Try parsing only the first valid JSON object using raw_decode\n",
    "                    cleaned = entry.strip('\"')\n",
    "                    fixed, _ = decoder.raw_decode(cleaned)\n",
    "            except Exception:\n",
    "                continue\n",
    "\n",
    "            if fixed:\n",
    "                break\n",
    "\n",
    "        if fixed:\n",
    "            # Dump back as compact JSON string\n",
    "            fixed_data.append(json.dumps(fixed, ensure_ascii=False))\n",
    "        else:\n",
    "            print(f\"[Error] Entry {i} could not be fixed: Extra data or malformed structure.\")\n",
    "\n",
    "    # Save all fixed entries\n",
    "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "    with open(output_path, 'w', encoding='utf-8') as f_out:\n",
    "        json.dump(fixed_data, f_out, indent=2, ensure_ascii=False)\n",
    "\n",
    "    print(f\"Fixed {len(fixed_data)} entries. Saved to {output_path}\")\n",
    "\n",
    "\n",
    "fix_and_validate_json(\"persona_analysis_data/workplace.json\", \"persona_analysis_data/fixed_workplace.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import difflib\n",
    "# File paths\n",
    "file1 = \"persona_analysis_data/workplace.json\"\n",
    "file2 = \"persona_analysis_data/fixed_workplace.json\"\n",
    "\n",
    "with open(file1, 'r') as f1, open(file2, 'r') as f2:\n",
    "    f1_lines = f1.readlines()\n",
    "    f2_lines = f2.readlines()\n",
    "\n",
    "# Compare line-by-line\n",
    "for i, (line1, line2) in enumerate(zip(f1_lines, f2_lines), 1):\n",
    "    if line1 != line2:\n",
    "        print(f\"Line {i} differs:\")\n",
    "\n",
    "        sm = difflib.SequenceMatcher(None, line1.strip(), line2.strip())\n",
    "        line1_diff = []\n",
    "        line2_diff = []\n",
    "\n",
    "        for op, i1, i2, j1, j2 in sm.get_opcodes():\n",
    "            if op == 'equal':\n",
    "                line1_diff.append(line1[i1:i2])\n",
    "                line2_diff.append(line2[j1:j2])\n",
    "            elif op == 'replace':\n",
    "                line1_diff.append(f\"[{line1[i1:i2]}]\")\n",
    "                line2_diff.append(f\"[{line2[j1:j2]}]\")\n",
    "            elif op == 'delete':\n",
    "                line1_diff.append(f\"[-{line1[i1:i2]}-]\")\n",
    "            elif op == 'insert':\n",
    "                line2_diff.append(f\"[+{line2[j1:j2]}+]\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thematic file saved to: persona_analysis_data/dating_neg_thematic_analysis.txt\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "# Input files\n",
    "dialogue_file = \"persona_generated_data/dating_convos_neg.json\"\n",
    "responses_file = \"persona_analysis_data/dating_neg.json\"\n",
    "output_file = \"persona_analysis_data/dating_neg_thematic_analysis.txt\"\n",
    "\n",
    "# Load raw dialogue and response strings\n",
    "with open(dialogue_file, 'r', encoding='utf-8') as f:\n",
    "    raw_dialogues = json.load(f)\n",
    "\n",
    "with open(responses_file, 'r', encoding='utf-8') as f:\n",
    "    raw_responses = json.load(f)\n",
    "\n",
    "# Write output\n",
    "with open(output_file, 'w', encoding='utf-8') as out_file:\n",
    "    for i, (dialogue_str, response_str) in enumerate(zip(raw_dialogues, raw_responses), 1):\n",
    "        try:\n",
    "            # --------------------------------------------\n",
    "            # ORIGINAL CONVERSATION (regex from raw string)\n",
    "            # --------------------------------------------\n",
    "            original_lines = re.findall(r'\"(Message by Person \\d+)\":\"(.*?)\"', dialogue_str)\n",
    "            original_text = \"\\n\".join([f\"{speaker}: {msg}\" for speaker, msg in original_lines])\n",
    "\n",
    "            # --------------------------------------------\n",
    "            # PARSE RESPONSE JSON\n",
    "            # --------------------------------------------\n",
    "            try:\n",
    "                response = json.loads(response_str)\n",
    "                if isinstance(response, str):\n",
    "                    response = json.loads(response)\n",
    "            except json.JSONDecodeError as e:\n",
    "                out_file.write(f\"[Error parsing entry {i}]: Invalid JSON in response. {str(e)}\\n\\n\")\n",
    "                continue\n",
    "\n",
    "            # --------------------------------------------\n",
    "            # MODIFIED CONVERSATION (regex from raw string)\n",
    "            # --------------------------------------------\n",
    "            updated_text = \"\"\n",
    "            # Look for the Modified Conversation block in the raw response string to preserve repeated keys\n",
    "            mod_conv_match = re.search(\n",
    "                r'\"Modified Conversation\"\\s*:\\s*{(.*?)}\\s*,\\s*\"(?:Decision|Explanation)\"',\n",
    "                response_str,\n",
    "                re.DOTALL\n",
    "            )\n",
    "\n",
    "            if mod_conv_match:\n",
    "                mod_conv_block = mod_conv_match.group(1)\n",
    "                updated_lines = re.findall(r'\"(Person \\d+)\":\\s*\"(.*?)\"', mod_conv_block)\n",
    "                updated_text = \"\\n\".join([f\"{speaker}: {msg}\" for speaker, msg in updated_lines])\n",
    "            else:\n",
    "                updated_text = \"  [Modified conversation not found or malformed]\"\n",
    "\n",
    "            # --------------------------------------------\n",
    "            # Extract other fields\n",
    "            # --------------------------------------------\n",
    "            decision = response.get(\"Decision\", \"N/A\")\n",
    "            explanation = response.get(\"Explanation\", \"N/A\")\n",
    "\n",
    "            # --------------------------------------------\n",
    "            # WRITE TO FILE\n",
    "            # --------------------------------------------\n",
    "            out_file.write(f\"--- Entry {i} ---\\n\")\n",
    "\n",
    "            out_file.write(\"Original Conversation:\\n\")\n",
    "            out_file.write(original_text + \"\\n\\n\")\n",
    "\n",
    "            out_file.write(\"Modified Conversation:\\n\")\n",
    "            out_file.write(updated_text if updated_text else \"  [Not provided]\\n\")\n",
    "            out_file.write(\"\\n\\n\")\n",
    "\n",
    "            out_file.write(\"Decision:\\n\")\n",
    "            out_file.write(f\"  {decision}\\n\\n\")\n",
    "\n",
    "            out_file.write(\"Explanation:\\n\")\n",
    "            out_file.write(f\"  {explanation}\\n\\n\\n\")\n",
    "\n",
    "        except Exception as e:\n",
    "            out_file.write(f\"[Unexpected error on entry {i}]: {str(e)}\\n\\n\")\n",
    "\n",
    "print(f\"Thematic file saved to: {output_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *Persona Based Analysis* - Dating #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Generate Dating Persona Data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Generate Categories**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Generate Negative Categories**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dating_categories():\n",
    "  return generate(model = '4o-mini',\n",
    "        system = \"Generate conversation topics as instructed below.\",\n",
    "        query = 'Generate a list of 60 difficult, tricky or conflict-prone conversation topics that commonly arise between married couples. Focus on emotionally complex, tense, or challenging subjects — including but not limited to disagreements, unmet expectations, financial strain, intimacy issues, parenting conflicts, resentment, long-term planning stress, co-living with in-laws. The topics should reflect realistic situations that could lead to disagreement, discomfort, or tension. Output only a list of topics formatted strictly in JSON (no markdown or code formatting) like a Python list of strings: [\"topic1\", \"topic2\",...,\"topic60\"]',\n",
    "        temperature=1,\n",
    "        lastk=0,\n",
    "        session_id='new',\n",
    "        rag_usage = True,\n",
    "        rag_threshold = 0,\n",
    "        rag_k = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = generate_dating_categories()['response']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54\n"
     ]
    }
   ],
   "source": [
    "results_list = json.loads(results)\n",
    "print(len(results_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('persona_generated_data/dating_topics_neg.json', 'w') as f:\n",
    "    json.dump(results, f, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Generate Positive Categories**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dating_categories():\n",
    "  return generate(model = '4o-mini',\n",
    "        system = \"Generate conversation topics as instructed below.\",\n",
    "        query = 'Generate a list of 60 neutral or positive different conversation topics that commonly occur between married couples. Include topics that reflect everyday life, shared responsibilities, lighthearted moments, emotional connection, support, future planning, romantic interactions, and other, similar aspects of married life. Output only a list of topics formatted strictly in JSON (no markdown or code formatting) like a Python list of strings: [\"topic1\", \"topic2\",...,\"topic60\"]',\n",
    "        temperature=1,\n",
    "        lastk=0,\n",
    "        session_id='new',\n",
    "        rag_usage = True,\n",
    "        rag_threshold = 0,\n",
    "        rag_k = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = generate_dating_categories()['response']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52\n"
     ]
    }
   ],
   "source": [
    "results_list = json.loads(results)\n",
    "print(len(results_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('persona_generated_data/dating_topics_pos.json', 'w') as f:\n",
    "    json.dump(results, f, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Generate Conversations**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Generate Negative Conversations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"persona_generated_data/dating_topics_neg.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    topics = json.load(f)  # This gives you a Python list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 370,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics_list = json.loads(topics)[0:5]\n",
    "len(topics_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dating_interaction(topic):\n",
    "  return generate(model = '4o-mini',\n",
    "        system = \"Generate personas of two humans and a conversation between them.\",\n",
    "        query = 'Imagine two individuals who are married to each other, then create a difficult or conflict-prone conversation between them on the following topic: ' + topic + '. The exchange should consist of no more than 6 messages. Do not use names or pronouns. Output only in the following JSON format (no markdown or code formatting) using the EXACT keys: {\"Message by Person 1 or 2\":\"message\",\"Message by Person 1 or 2\":\"message\",...}.',\n",
    "        temperature=1,\n",
    "        lastk=0,\n",
    "        session_id='new',\n",
    "        rag_usage = True,\n",
    "        rag_threshold = 0,\n",
    "        rag_k = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dialogue(topic):\n",
    "    return generate_dating_interaction(topic)['response']\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=10) as executor:\n",
    "    results = list(executor.map(process_dialogue, topics_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('persona_generated_data/dating_convos_neg.json', 'w') as f:\n",
    "    json.dump(results, f, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Generate Positive Conversations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"persona_generated_data/dating_topics_pos.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    topics = json.load(f)  # This gives you a Python list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics_list = json.loads(topics)[0:50]\n",
    "len(topics_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dating_interaction(topic):\n",
    "  return generate(model = '4o-mini',\n",
    "        system = \"Generate personas of two humans and a conversation between them.\",\n",
    "        query = 'Generate personas for two individuals who are married to each other, then create a positive/neutral conversation between them on the following topic: ' + topic + '. The exchange should consist of no more than 4 messages. Do not use names or pronouns. Do not use names or pronouns. Output only in the following JSON format (no markdown or code formatting) using the EXACT keys: {\"Message by Person 1 or 2\":\"message\",\"Message by Person 1 or 2\":\"message\",...}.',\n",
    "        temperature=1,\n",
    "        lastk=0,\n",
    "        session_id='new',\n",
    "        rag_usage = True,\n",
    "        rag_threshold = 0,\n",
    "        rag_k = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dialogue(topic):\n",
    "    return generate_dating_interaction(topic)['response']\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=10) as executor:\n",
    "    results = list(executor.map(process_dialogue, topics_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('persona_generated_data/dating_convos_pos.json', 'w') as f:\n",
    "    json.dump(results, f, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Analyse Dating Persona Data** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Analysing Negative Conversations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_dating_persona(dialogue):\n",
    "  return generate(model = 'gpt-4o',\n",
    "        system = 'Modify and analyse the dialogue as instructed below.',\n",
    "        query = dialogue + '\\n\\nThe dialogue above shows two married individuals having a difficult or conflict-prone conversation. Modify the conversation (focus on how the partners communicate with each another) to reflect how they would have navigated this conversation if one of them was autistic. Choose one person to be autistic, based on their communication style. Explain your reasoning thoroughly. Output your response in the following JSON format (no markdown or code formatting) using these EXACT keys: {\"Modified Conversation\":{\"Person 1\":\"their statement...\", \"Person 2\": \"their statement...\",...}, \"Decision\": \"Person 1 or Person 2\", \"Explanation\":\"A detailed explanation why you think one person is autistic and the other is not. Compare their communication styles and the norms they seem to be following. Provide specific reasons. Avoid broad remarks, such as \\'Person X reflects characteristics often associated with autistic communication styles.\\'\"}',\n",
    "        temperature=1,\n",
    "        lastk=0,\n",
    "        session_id='new',\n",
    "        rag_usage = True,\n",
    "        rag_threshold = 0,\n",
    "        rag_k = 0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# dialogue + '\\n\\nThe dialogue above shows two married individuals having a conflict-prone, sensitive conversation. Modify the communication style of one or both partners to reflect how they would navigate the conversation if one of them were autistic. Based on their communication styles in the updated conversation, identify which person you would consider autistic and explain your reasoning. Explain your reasoning thoroughly, referencing specific statements from the conversation to support it. Output your response in the following JSON format (no markdown or code formatting) using these EXACT keys: {\"Modified Conversation\":{\"Person 1\":\"their statement...\", \"Person 2\": \"their statement...\",...}, \"Decision\": \"Person 1 or Person 2\", \"Autistic-Explanation:\":\"Detailed and specific explanation why you think which person is autistic.\", \"Non-Autistic-Explanation\":\"Detailed and specific explanation why you think which person is non-autistic.\"}',\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['{\"Message by Person 1\":\"It\\'s time we have a serious talk about our spending habits. The savings account is nearly empty and we can\\'t keep ignoring it.\",\"Message by Person 2\":\"I know it\\'s tight right now, but I just don’t think we should cut back on small luxuries. They make life enjoyable.\",\"Message by Person 1\":\"But those luxuries are adding up! A couple of dinners out a week can easily derail our budget, especially with the upcoming expenses.\",\"Message by Person 2\":\"I understand that, but we need to enjoy our lives too. I work hard, and I feel like I deserve some rewards for that effort.\",\"Message by Person 1\":\"It\\'s not about not enjoying life; it\\'s about setting priorities. We have future goals that we need to start saving for, like a house.\",\"Message by Person 2\":\"I get that, but it feels like every conversation about money turns into a lecture. Can\\'t we find a balance without sacrificing everything?\"}',\n",
       " '{\"Message by Person 1\":\"It\\'s really frustrating that I\\'m doing most of the chores around here. I feel overwhelmed with everything piling up.\",\"Message by Person 2\":\"I understand, but I have been busy with work lately and haven\\'t had the same time to help out. It\\'s not that I don\\'t care.\",\"Message by Person 1\":\"It doesn\\'t feel fair that one person is carrying the weight while the other gets a free pass. Can\\'t we find a better way to divide this?\",\"Message by Person 2\":\"I thought we agreed that I would handle the laundry and you would manage the kitchen. It\\'s hard to keep track of everything when plans change.\",\"Message by Person 1\":\"But the laundry is only done once a week, while dishes and cleaning happen daily. It feels lopsided to me.\",\"Message by Person 2\":\"Maybe we need to sit down and create a better schedule, but it can\\'t just be one person\\'s responsibility to manage everything.\"}']"
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('persona_generated_data/dating_convos_neg.json') as f:\n",
    "    results_loaded = json.load(f)\n",
    "\n",
    "results_loaded[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dialogue(i):\n",
    "    dialogue = results_loaded[i]\n",
    "    response = analyze_dating_persona(dialogue)['response']\n",
    "    return response\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=10) as executor:\n",
    "    results = list(executor.map(process_dialogue, range(5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('persona_analysis_data/dating_neg.json', 'w') as f:\n",
    "    json.dump(results, f, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Process Dating Persona Analysis Data** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thematic file saved to: persona_analysis_data/dating_them_neg.txt\n"
     ]
    }
   ],
   "source": [
    "# Input files\n",
    "dialogue_file = \"persona_generated_data/dating_convos_neg.json\"\n",
    "responses_file = \"persona_analysis_data/dating_neg.json\"\n",
    "output_file = \"persona_analysis_data/dating_them_neg.txt\"\n",
    "\n",
    "# Load raw dialogue and response strings\n",
    "with open(dialogue_file, 'r', encoding='utf-8') as f:\n",
    "    raw_dialogues = json.load(f)\n",
    "\n",
    "with open(responses_file, 'r', encoding='utf-8') as f:\n",
    "    raw_responses = json.load(f)\n",
    "\n",
    "# Write output\n",
    "with open(output_file, 'w', encoding='utf-8') as out_file:\n",
    "    for i, (dialogue_str, response_str) in enumerate(zip(raw_dialogues, raw_responses), 1):\n",
    "        try:\n",
    "            # --------------------------------------------\n",
    "            # ORIGINAL CONVERSATION (regex from raw string)\n",
    "            # --------------------------------------------\n",
    "            original_lines = re.findall(r'\"(Message by Person \\d+)\":\"(.*?)\"', dialogue_str)\n",
    "            original_text = \"\\n\".join([f\"{speaker}: {msg}\" for speaker, msg in original_lines])\n",
    "\n",
    "            # --------------------------------------------\n",
    "            # PARSE RESPONSE JSON\n",
    "            # --------------------------------------------\n",
    "            try:\n",
    "                response = json.loads(response_str)\n",
    "                if isinstance(response, str):\n",
    "                    response = json.loads(response)\n",
    "            except json.JSONDecodeError as e:\n",
    "                out_file.write(f\"[Error parsing entry {i}]: Invalid JSON in response. {str(e)}\\n\\n\")\n",
    "                continue\n",
    "\n",
    "            # --------------------------------------------\n",
    "            # MODIFIED CONVERSATION (regex from raw string)\n",
    "            # --------------------------------------------\n",
    "            updated_text = \"\"\n",
    "            # Look for the Modified Conversation block in the raw response string to preserve repeated keys\n",
    "            mod_conv_match = re.search(\n",
    "                r'\"Modified Conversation\"\\s*:\\s*{(.*?)}\\s*,\\s*\"(?:Decision|Explanation)\"',\n",
    "                response_str,\n",
    "                re.DOTALL\n",
    "            )\n",
    "\n",
    "            if mod_conv_match:\n",
    "                mod_conv_block = mod_conv_match.group(1)\n",
    "                updated_lines = re.findall(r'\"(Person \\d+)\":\\s*\"(.*?)\"', mod_conv_block)\n",
    "                updated_text = \"\\n\".join([f\"{speaker}: {msg}\" for speaker, msg in updated_lines])\n",
    "            else:\n",
    "                updated_text = \"  [Modified conversation not found or malformed]\"\n",
    "\n",
    "            # --------------------------------------------\n",
    "            # Extract other fields\n",
    "            # --------------------------------------------\n",
    "            decision = response.get(\"Decision\", \"N/A\")\n",
    "            # a_exp = response.get(\"Autistic-Explanation\", \"N/A\")\n",
    "            # non_a_exp = response.get(\"Non-Autistic-Explanation\", \"N/A\")\n",
    "            explanation = response.get(\"Explanation\", \"N/A\")\n",
    "\n",
    "            # --------------------------------------------\n",
    "            # WRITE TO FILE\n",
    "            # --------------------------------------------\n",
    "            out_file.write(f\"--- Entry {i} ---\\n\")\n",
    "\n",
    "            out_file.write(\"Original Conversation:\\n\")\n",
    "            out_file.write(original_text + \"\\n\\n\")\n",
    "\n",
    "            out_file.write(\"Modified Conversation:\\n\")\n",
    "            out_file.write(updated_text if updated_text else \"  [Not provided]\\n\")\n",
    "            out_file.write(\"\\n\\n\")\n",
    "\n",
    "            out_file.write(\"Decision:\\n\")\n",
    "            out_file.write(f\"  {decision}\\n\\n\")\n",
    "\n",
    "            out_file.write(\"Explanation:\\n\")\n",
    "            out_file.write(f\"  {explanation}\\n\\n\\n\")\n",
    "\n",
    "            # out_file.write(\"Autistic Explanation:\\n\")\n",
    "            # out_file.write(f\"  {a_exp}\\n\\n\\n\")\n",
    "\n",
    "            # out_file.write(\"Non-Autistic Explanation:\\n\")\n",
    "            # out_file.write(f\"  {non_a_exp}\\n\\n\\n\")\n",
    "\n",
    "\n",
    "\n",
    "        except Exception as e:\n",
    "            out_file.write(f\"[Unexpected error on entry {i}]: {str(e)}\\n\\n\")\n",
    "\n",
    "print(f\"Thematic file saved to: {output_file}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
