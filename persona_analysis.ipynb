{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import ast\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from shared import generate\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *Persona Based Analysis* - Workplace #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Generate Workplace Persona Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_workplace_interaction():\n",
    "  return generate(model = '4o-mini',\n",
    "        system = \"Generate fictional personas for two individuals who are professional colleagues. Use these personas to write a brief workplace dialogue.\",\n",
    "        query = 'Write a professional workplace interaction between the two colleagues imagined above. Limit the exchange to no more than 4 messages. Do not use names or pronouns. Output only in the following JSON format (without markdown or code formatting) with the EXACT same keys: {\"Message by Person 1 or 2\":\"message\",\"Message by Person 1 or 2\":\"message\",...}.',\n",
    "        temperature=1.5,\n",
    "        lastk=0,\n",
    "        session_id='new',\n",
    "        rag_usage = True,\n",
    "        rag_threshold = 0,\n",
    "        rag_k = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dialogue(i):\n",
    "    return generate_workplace_interaction()['response']\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=10) as executor:\n",
    "    results = list(executor.map(process_dialogue, range(100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('persona_generated_data/workplace.json', 'w') as f:\n",
    "    json.dump(results, f, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Analyse Workplace Persona Data** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_workplace_persona(dialogue):\n",
    "  return generate(model = '4o-mini',\n",
    "        system = 'Analyze the dialogue as specified below.',\n",
    "        query = dialogue + '\\n\\nThe dialogue above features two colleagues. Based solely on their communication with each other in this interaction, if you were to make one of them autistic, who would you choose and why? Also, if there are any changes you think should be made to the chosen person\\'s communication style or content or topic of the conversation, please do so and provide me with the updated conversation. Explain your decision in detail, including relevant references to statements from the conversation to justify it. Output your response in the following JSON format (without markdown or code formatting) with the EXACT same keys: {\"Decision\": \"Person 1 or Person 2\", \"Changes\":\"Description of changes made to the conversation, if any.\", \"Updated Conversation\":{\"Person 1\":\"their statement...\", \"Person 2\": \"their statement...\"}, \"Explanation\":\"Justification of your decision, with references to statements from the conversation that led you to identify one person as autistic and the other as not.\",}',\n",
    "        temperature=1,\n",
    "        lastk=0,\n",
    "        session_id='new',\n",
    "        rag_usage = True,\n",
    "        rag_threshold = 0,\n",
    "        rag_k = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['{\"Message by Person 1\":\"The quarterly report is due next week. Have all the metrics been reviewed for accuracy?\",\"Message by Person 2\":\"I finished analyzing the data yesterday. I\\'m just compiling it into the presentation format now.\",\"Message by Person 1\":\"Great! Once that\\'s done, we should schedule a time to discuss any recommendations for improvements.\",\"Message by Person 2\":\"Sounds perfect. I will aim to have it ready by tomorrow afternoon.\"}',\n",
       " '{\"Message by Person 1\":\"The marketing presentation is due next week. I hope the graphics are ready by tomorrow.\",\"Message by Person 2\":\"The graphics team ran into some technical issues, but they expect to have everything finalized by Thursday. Hoping that\\'s soon enough for us.\",\"Message by Person 1\":\"That works. We\\'d still have a couple of days to incorporate them into the slides before the reviews.\",\"Message by Person 2\":\"Exactly! I’ll touch base with the graphics team and make sure they stay on track.\"}']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('persona_generated_data/workplace.json') as f:\n",
    "    results_loaded = json.load(f)\n",
    "\n",
    "results_loaded[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dialogue(i):\n",
    "    dialogue = results_loaded[i]\n",
    "    response = analyze_workplace_persona(dialogue)['response']\n",
    "    return response\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=10) as executor:\n",
    "    results = list(executor.map(process_dialogue, range(100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('persona_analysis_data/workplace.json', 'w') as f:\n",
    "    json.dump(results, f, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Process Workplace Persona Analysis Data** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fixed 100 entries. Saved to persona_analysis_data/fixed_workplace.json\n"
     ]
    }
   ],
   "source": [
    "def fix_and_validate_json(input_path, output_path):\n",
    "    with open(input_path, 'r', encoding='utf-8') as f:\n",
    "        raw_data = json.load(f)\n",
    "\n",
    "    fixed_data = []\n",
    "    decoder = json.JSONDecoder()\n",
    "\n",
    "    for i, entry in enumerate(raw_data, 1):\n",
    "        if not isinstance(entry, str):\n",
    "            print(f\"[Warning] Entry {i} is not a string. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        fixed = None\n",
    "\n",
    "        # Try multiple parsing approaches\n",
    "        for attempt in range(3):\n",
    "            try:\n",
    "                if attempt == 0:\n",
    "                    fixed = json.loads(entry)\n",
    "                elif attempt == 1:\n",
    "                    # Unescape unicode, then parse\n",
    "                    unescaped = entry.encode('utf-8').decode('unicode_escape')\n",
    "                    fixed = json.loads(unescaped)\n",
    "                elif attempt == 2:\n",
    "                    # Try parsing only the first valid JSON object using raw_decode\n",
    "                    cleaned = entry.strip('\"')\n",
    "                    fixed, _ = decoder.raw_decode(cleaned)\n",
    "            except Exception:\n",
    "                continue\n",
    "\n",
    "            if fixed:\n",
    "                break\n",
    "\n",
    "        if fixed:\n",
    "            # Dump back as compact JSON string\n",
    "            fixed_data.append(json.dumps(fixed, ensure_ascii=False))\n",
    "        else:\n",
    "            print(f\"[Error] Entry {i} could not be fixed: Extra data or malformed structure.\")\n",
    "\n",
    "    # Save all fixed entries\n",
    "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "    with open(output_path, 'w', encoding='utf-8') as f_out:\n",
    "        json.dump(fixed_data, f_out, indent=2, ensure_ascii=False)\n",
    "\n",
    "    print(f\"Fixed {len(fixed_data)} entries. Saved to {output_path}\")\n",
    "\n",
    "\n",
    "fix_and_validate_json(\"persona_analysis_data/workplace.json\", \"persona_analysis_data/fixed_workplace.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import difflib\n",
    "# File paths\n",
    "file1 = \"persona_analysis_data/workplace.json\"\n",
    "file2 = \"persona_analysis_data/fixed_workplace.json\"\n",
    "\n",
    "with open(file1, 'r') as f1, open(file2, 'r') as f2:\n",
    "    f1_lines = f1.readlines()\n",
    "    f2_lines = f2.readlines()\n",
    "\n",
    "# Compare line-by-line\n",
    "for i, (line1, line2) in enumerate(zip(f1_lines, f2_lines), 1):\n",
    "    if line1 != line2:\n",
    "        print(f\"Line {i} differs:\")\n",
    "\n",
    "        sm = difflib.SequenceMatcher(None, line1.strip(), line2.strip())\n",
    "        line1_diff = []\n",
    "        line2_diff = []\n",
    "\n",
    "        for op, i1, i2, j1, j2 in sm.get_opcodes():\n",
    "            if op == 'equal':\n",
    "                line1_diff.append(line1[i1:i2])\n",
    "                line2_diff.append(line2[j1:j2])\n",
    "            elif op == 'replace':\n",
    "                line1_diff.append(f\"[{line1[i1:i2]}]\")\n",
    "                line2_diff.append(f\"[{line2[j1:j2]}]\")\n",
    "            elif op == 'delete':\n",
    "                line1_diff.append(f\"[-{line1[i1:i2]}-]\")\n",
    "            elif op == 'insert':\n",
    "                line2_diff.append(f\"[+{line2[j1:j2]}+]\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thematic file saved to: persona_analysis_data/dating_neg_thematic_analysis.txt\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "# Input files\n",
    "dialogue_file = \"persona_generated_data/dating_convos_neg.json\"\n",
    "responses_file = \"persona_analysis_data/dating_neg.json\"\n",
    "output_file = \"persona_analysis_data/dating_neg_thematic_analysis.txt\"\n",
    "\n",
    "# Load raw dialogue and response strings\n",
    "with open(dialogue_file, 'r', encoding='utf-8') as f:\n",
    "    raw_dialogues = json.load(f)\n",
    "\n",
    "with open(responses_file, 'r', encoding='utf-8') as f:\n",
    "    raw_responses = json.load(f)\n",
    "\n",
    "# Write output\n",
    "with open(output_file, 'w', encoding='utf-8') as out_file:\n",
    "    for i, (dialogue_str, response_str) in enumerate(zip(raw_dialogues, raw_responses), 1):\n",
    "        try:\n",
    "            # --------------------------------------------\n",
    "            # ORIGINAL CONVERSATION (regex from raw string)\n",
    "            # --------------------------------------------\n",
    "            original_lines = re.findall(r'\"(Message by Person \\d+)\":\"(.*?)\"', dialogue_str)\n",
    "            original_text = \"\\n\".join([f\"{speaker}: {msg}\" for speaker, msg in original_lines])\n",
    "\n",
    "            # --------------------------------------------\n",
    "            # PARSE RESPONSE JSON\n",
    "            # --------------------------------------------\n",
    "            try:\n",
    "                response = json.loads(response_str)\n",
    "                if isinstance(response, str):\n",
    "                    response = json.loads(response)\n",
    "            except json.JSONDecodeError as e:\n",
    "                out_file.write(f\"[Error parsing entry {i}]: Invalid JSON in response. {str(e)}\\n\\n\")\n",
    "                continue\n",
    "\n",
    "            # --------------------------------------------\n",
    "            # MODIFIED CONVERSATION (regex from raw string)\n",
    "            # --------------------------------------------\n",
    "            updated_text = \"\"\n",
    "            # Look for the Modified Conversation block in the raw response string to preserve repeated keys\n",
    "            mod_conv_match = re.search(\n",
    "                r'\"Modified Conversation\"\\s*:\\s*{(.*?)}\\s*,\\s*\"(?:Decision|Explanation)\"',\n",
    "                response_str,\n",
    "                re.DOTALL\n",
    "            )\n",
    "\n",
    "            if mod_conv_match:\n",
    "                mod_conv_block = mod_conv_match.group(1)\n",
    "                updated_lines = re.findall(r'\"(Person \\d+)\":\\s*\"(.*?)\"', mod_conv_block)\n",
    "                updated_text = \"\\n\".join([f\"{speaker}: {msg}\" for speaker, msg in updated_lines])\n",
    "            else:\n",
    "                updated_text = \"  [Modified conversation not found or malformed]\"\n",
    "\n",
    "            # --------------------------------------------\n",
    "            # Extract other fields\n",
    "            # --------------------------------------------\n",
    "            decision = response.get(\"Decision\", \"N/A\")\n",
    "            explanation = response.get(\"Explanation\", \"N/A\")\n",
    "\n",
    "            # --------------------------------------------\n",
    "            # WRITE TO FILE\n",
    "            # --------------------------------------------\n",
    "            out_file.write(f\"--- Entry {i} ---\\n\")\n",
    "\n",
    "            out_file.write(\"Original Conversation:\\n\")\n",
    "            out_file.write(original_text + \"\\n\\n\")\n",
    "\n",
    "            out_file.write(\"Modified Conversation:\\n\")\n",
    "            out_file.write(updated_text if updated_text else \"  [Not provided]\\n\")\n",
    "            out_file.write(\"\\n\\n\")\n",
    "\n",
    "            out_file.write(\"Decision:\\n\")\n",
    "            out_file.write(f\"  {decision}\\n\\n\")\n",
    "\n",
    "            out_file.write(\"Explanation:\\n\")\n",
    "            out_file.write(f\"  {explanation}\\n\\n\\n\")\n",
    "\n",
    "        except Exception as e:\n",
    "            out_file.write(f\"[Unexpected error on entry {i}]: {str(e)}\\n\\n\")\n",
    "\n",
    "print(f\"Thematic file saved to: {output_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *Persona Based Analysis* - Dating #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Generate Negative Categories (ignore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def generate_dating_categories():\n",
    "#   return generate(model = '4o-mini',\n",
    "#         system = \"Generate conversation topics as instructed below.\",\n",
    "#         query = 'Generate a list of 60 difficult, tricky or conflict-prone conversation topics that commonly arise between married couples. Focus on emotionally complex, tense, or challenging subjects — including but not limited to disagreements, unmet expectations, financial strain, intimacy issues, parenting conflicts, resentment, long-term planning stress, co-living with in-laws. The topics should reflect realistic situations that could lead to disagreement, discomfort, or tension. Output only a list of topics formatted strictly in JSON (no markdown or code formatting) like a Python list of strings: [\"topic1\", \"topic2\",...,\"topic60\"]',\n",
    "#         temperature=1,\n",
    "#         lastk=0,\n",
    "#         session_id='new',\n",
    "#         rag_usage = True,\n",
    "#         rag_threshold = 0,\n",
    "#         rag_k = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results = generate_dating_categories()['response']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54\n"
     ]
    }
   ],
   "source": [
    "# results_list = json.loads(results)\n",
    "# print(len(results_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('persona_generated_data/dating_topics_neg.json', 'w') as f:\n",
    "#     json.dump(results, f, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Generate Positive Categories (ignore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def generate_dating_categories():\n",
    "#   return generate(model = '4o-mini',\n",
    "#         system = \"Generate conversation topics as instructed below.\",\n",
    "#         query = 'Generate a list of 60 neutral or positive different conversation topics that commonly occur between married couples. Include topics that reflect everyday life, shared responsibilities, lighthearted moments, emotional connection, support, future planning, romantic interactions, and other, similar aspects of married life. Output only a list of topics formatted strictly in JSON (no markdown or code formatting) like a Python list of strings: [\"topic1\", \"topic2\",...,\"topic60\"]',\n",
    "#         temperature=1,\n",
    "#         lastk=0,\n",
    "#         session_id='new',\n",
    "#         rag_usage = True,\n",
    "#         rag_threshold = 0,\n",
    "#         rag_k = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results = generate_dating_categories()['response']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52\n"
     ]
    }
   ],
   "source": [
    "# results_list = json.loads(results)\n",
    "# print(len(results_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('persona_generated_data/dating_topics_pos.json', 'w') as f:\n",
    "#     json.dump(results, f, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Generate Negative Conversations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"persona_generated_data/dating_topics_neg.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    topics = json.load(f)  # This gives you a Python list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics_list = topics[0:50]\n",
    "len(topics_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dating_interaction(topic):\n",
    "  #4o-mini\n",
    "  return generate(model = 'gpt-4o',\n",
    "        system = \"Generate personas of two humans and a conversation between them.\",\n",
    "        query = 'Imagine two married individuals having a difficult, confrontational, or conflict-prone conversation in which one of them is clearly at fault. Create the conversation based on the following topic: ' + topic + '. The exchange should consist of no more than 6 messages. Do not use names or pronouns. Output only in the following format (no markdown or code formatting) using these EXACT keys: {\"Message by Person 1 or 2\":\"message\",\"Message by Person 1 or 2\":\"message\",...}.',\n",
    "        temperature=1,\n",
    "        lastk=0,\n",
    "        session_id='new',\n",
    "        rag_usage = True,\n",
    "        rag_threshold = 0,\n",
    "        rag_k = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dialogue(topic):\n",
    "    return generate_dating_interaction(topic)['response']\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=10) as executor:\n",
    "    results = list(executor.map(process_dialogue, topics_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('persona_generated_data/dating_convos_neg.json', 'w') as f:\n",
    "    json.dump(results, f, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Generate Positive Conversations (ignore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"persona_generated_data/dating_topics_pos.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "#     topics = json.load(f)  # This gives you a Python list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# topics_list = json.loads(topics)[0:50]\n",
    "# len(topics_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def generate_dating_interaction(topic):\n",
    "#   return generate(model = '4o-mini',\n",
    "#         system = \"Generate personas of two humans and a conversation between them.\",\n",
    "#         query = 'Generate personas for two individuals who are married to each other, then create a positive/neutral conversation between them on the following topic: ' + topic + '. The exchange should consist of no more than 4 messages. Do not use names or pronouns. Do not use names or pronouns. Output only in the following JSON format (no markdown or code formatting) using the EXACT keys: {\"Message by Person 1 or 2\":\"message\",\"Message by Person 1 or 2\":\"message\",...}.',\n",
    "#         temperature=1,\n",
    "#         lastk=0,\n",
    "#         session_id='new',\n",
    "#         rag_usage = True,\n",
    "#         rag_threshold = 0,\n",
    "#         rag_k = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def process_dialogue(topic):\n",
    "#     return generate_dating_interaction(topic)['response']\n",
    "\n",
    "# with ThreadPoolExecutor(max_workers=10) as executor:\n",
    "#     results = list(executor.map(process_dialogue, topics_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('persona_generated_data/dating_convos_pos.json', 'w') as f:\n",
    "#     json.dump(results, f, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Analyse Negative Conversations (identify autistic communication style)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_dating_persona(dialogue):\n",
    "  return generate(model = 'gpt-4o',\n",
    "        system = 'Modify and analyse the dialogue as instructed below.',\n",
    "        query = dialogue + '\\n\\nThe dialogue above shows two married individuals having a difficult or conflict-prone conversation. Modify the conversation (focusing on how the partners communicate with each another, as well as the content of the conversation) to reflect how they would have navigated this conversation if one of them was autistic. Choose one person to be autistic. Explain your reasoning for your decision thoroughly. Output your response in the following format (no markdown or code formatting) using these EXACT keys: {\"Modified Conversation\":{\"Person 1\":\"their statement...\", \"Person 2\": \"their statement...\",...}, \"Decision\": \"Person 1 or Person 2\", \"Explanation\":\"An in-depth breakdown/explanation why you think one person is autistic and the other is not, comparing the communication styles of both speakers. Specifically, analyze how each person conveys their thoughts, emotions, or intentions, responds to each other, and their choice of words and language. Provide specific reasons.}',\n",
    "        temperature=1,\n",
    "        lastk=0,\n",
    "        session_id='new',\n",
    "        rag_usage = True,\n",
    "        rag_threshold = 0,\n",
    "        rag_k = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['{\"Message by Person 1\":\"I saw the messages. How long has this been going on?\",\"Message by Person 2\":\"It\\'s not what it looks like. Please let me explain.\",\"Message by Person 1\":\"Explain what? I trusted you, and you betrayed that trust.\",\"Message by Person 2\":\"I made a mistake, but it didn\\'t mean anything. I swear it will never happen again.\",\"Message by Person 1\":\"A mistake? How many more \\'mistakes\\' have there been?\",\"Message by Person 2\":\"None, this was the only time. I\\'m so sorry. Please, let’s try to work through this together.\"}',\n",
       " '{\"Message by Person 1\":\"I\\'ve noticed that we haven\\'t been intimate in a while and it\\'s been bothering me.\",\"Message by Person 2\":\"It\\'s just that I\\'ve lost interest lately and I\\'m not sure why.\",\"Message by Person 1\":\"But why didn\\'t you talk to me about it? It feels like we\\'re growing apart.\",\"Message by Person 2\":\"I\\'m sorry. I was embarrassed and didn\\'t want to hurt your feelings.\",\"Message by Person 1\":\"I understand, but we need to work through this together. Ignoring it won\\'t help.\",\"Message by Person 2\":\"You\\'re right. Let\\'s find a way to address this and get our connection back.\"}']"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('persona_generated_data/dating_convos_neg.json') as f:\n",
    "    results_loaded = json.load(f)\n",
    "\n",
    "results_loaded[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dialogue(i):\n",
    "    dialogue = results_loaded[i]\n",
    "    response = analyze_dating_persona(dialogue)['response']\n",
    "    return response\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=10) as executor:\n",
    "    results = list(executor.map(process_dialogue, range(50)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('persona_analysis_data/dating_neg.json', 'w') as f:\n",
    "    json.dump(results, f, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Analyse Negative Conversations (identify blame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"persona_analysis_data/dating_them_neg.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    content = f.read()\n",
    "\n",
    "blocks = re.split(r\"-------\\d+-------\", content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "autistic = []\n",
    "\n",
    "for block in blocks:\n",
    "    match = re.search(r\"Decision:\\s*(.*?)\\n\\n\", block, re.S)\n",
    "    if match:\n",
    "        decision_value = match.group(1).strip()\n",
    "        autistic.append(decision_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "conversations = []\n",
    "\n",
    "pattern = re.compile(\n",
    "    r\"[#\\s]*Modified Conversation:?\\s*\\n\"        # heading, with hashes/spaces allowed\n",
    "    r\"(.*?)\"                                     # capture conversation\n",
    "    r\"(?=(?:\\n\\n\\s*Decision\\b)|\"                 # stop before \"Decision\"\n",
    "    r\"(?:\\n[-]{7}\\d+[-]{7})|\"                    # ...or before next block separator\n",
    "    r\"\\Z)\",                                      # ...or end of string\n",
    "    re.S | re.I\n",
    ")\n",
    "\n",
    "for block in blocks:\n",
    "    match = pattern.search(block)\n",
    "    if match:\n",
    "        modified_conv = match.group(1).strip()\n",
    "        conversations.append(modified_conv)\n",
    "    else:\n",
    "        print(block)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_blame(dialogue):\n",
    "  return generate(model = 'gpt-4o',\n",
    "        system = 'Decide which person bears responsibility.',\n",
    "        query = dialogue + '\\n\\nIn the above conversation between two married individuals, determine which person was at fault in the situation. Decide between Person 1, Person 2, Neither or Both. Output only one of these four EXACT words.',\n",
    "        temperature=1,\n",
    "        lastk=0,\n",
    "        session_id='new',\n",
    "        rag_usage = True,\n",
    "        rag_threshold = 0,\n",
    "        rag_k = 0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_response(i):\n",
    "    dialogue = conversations[i]\n",
    "    response = identify_blame(dialogue)['response']\n",
    "    return response\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=10) as executor:\n",
    "    final_responses = list(executor.map(process_response, range(50)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(\"persona_analysis_data/dating_them_neg_resp.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for a, b in zip(final_responses, autistic):\n",
    "        f.write(f\"{a}    {b}\\n\")  # 4 spaces for separation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Process Analysis Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_response(response):\n",
    "  return generate(model = 'gpt-4o',\n",
    "        system = 'Format the text in a more easily readable format.',\n",
    "        query = response + '\\n\\nReformat the provided JSON string into a readable plain-text format. Keep the three keys as headings and insert their values below the headings. Under \"Modified Conversation\", list each turn as \"Person 1:\" or \"Person 2:\" on its own line, in order. Do NOT change the wording of any values. Output only the reformatted string.',\n",
    "        temperature=1,\n",
    "        lastk=0,\n",
    "        session_id='new',\n",
    "        rag_usage = True,\n",
    "        rag_threshold = 0,\n",
    "        rag_k = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_conversation(json_like_str):\n",
    "    # Regex to match: \"Message by Person X\": \"some text...\"\n",
    "    pattern = r'\"Message by (Person \\d+)\":\"(.*?)\"'\n",
    "    \n",
    "    # Find all matches, including repeated keys\n",
    "    matches = re.findall(pattern, json_like_str)\n",
    "    \n",
    "    # Turn into readable string\n",
    "    dialogue_str = \"\\n\".join(f\"{speaker}: {message}\" for speaker, message in matches)\n",
    "    \n",
    "    return dialogue_str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input files\n",
    "dialogue_file = \"persona_generated_data/dating_convos_neg.json\"\n",
    "responses_file = \"persona_analysis_data/dating_neg.json\"\n",
    "output_file = \"persona_analysis_data/dating_them_neg.txt\"\n",
    "\n",
    "# Load raw dialogue and response strings\n",
    "with open(dialogue_file, 'r', encoding='utf-8') as f:\n",
    "    raw_dialogues = json.load(f)\n",
    "\n",
    "\n",
    "with open(responses_file, 'r', encoding='utf-8') as f:\n",
    "    raw_responses = json.load(f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_response(i):\n",
    "    raw_response = raw_responses[i]\n",
    "    raw_dialogue = parse_conversation(raw_dialogues[i])\n",
    "    response = format_response(raw_response)['response']\n",
    "    return \"-------\" + str(i) + \"-------\\n\\n\" + \"Original Conversation:\\n\" + raw_dialogue + \"\\n\\n\" + response \n",
    "\n",
    "with ThreadPoolExecutor(max_workers=10) as executor:\n",
    "    final_responses = list(executor.map(process_response, range(50)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"\\n\\n\".join(final_responses))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
